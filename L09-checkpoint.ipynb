{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 9 Practice: Supervised Machine Learning\n",
    "Use this notebook to follow along with the lesson in the corresponding lesson notebook: [L09-Supervised_Machine_Learning-Lesson.ipynb](./L09-Supervised_Machine_Learning-Lesson.ipynb).  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Follow along with the teaching material in the lesson. Throughout the tutorial sections labeled as \"Tasks\" are interspersed and indicated with the icon: ![Task](http://icons.iconarchive.com/icons/sbstnblnd/plateau/16/Apps-gnome-info-icon.png). You should follow the instructions provided in these sections by performing them in the practice notebook.  When the tutorial is completed you can turn in the final practice notebook. For each task, use the cell below it to write and test your code.  You may add additional cells for any task as needed or desired.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1a: Setup\n",
    "\n",
    "Import the following package sets:\n",
    "+ packages for data management\n",
    "+ pacakges for visualization\n",
    "+ packages for machine learning\n",
    "\n",
    "Remember to activate the `%matplotlib inline` magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Data Management\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine learning\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2a: Data Exploration\n",
    "\n",
    "After reviewing the data in sections 2.1, 2.2, 2.3 and 2.4 do you see any problems with this iris dataset? If so, please describe them in the practice notebook.  If not, simply indicate that there are no issues."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1) Species is an object. I would assume it needs to be a number if we are predicting its value\n",
    "\n",
    "2) We should remove the duplicate if it is infact a true duplicate\n",
    "\n",
    "3) we should remove the outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2b:  Make Assumptions\n",
    "\n",
    "After reviewing the data in sections 2.1, 2.2, 2.3 and 2.4 are there any columns that would make poor predictors of species? \n",
    "\n",
    "**Hint**: columns that are poor predictors are:\n",
    "+ those with too many missing values\n",
    "+ those with no difference in variation when grouped by the outcome class\n",
    "+ variables with high levels of collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.99599866 0.99997391 ... 0.65347343 0.6339168  0.63315839]\n",
      " [0.99599866 1.         0.99660709 ... 0.70898277 0.68625679 0.68483481]\n",
      " [0.99997391 0.99660709 1.         ... 0.65755616 0.63763128 0.6368058 ]\n",
      " ...\n",
      " [0.65347343 0.70898277 0.65755616 ... 1.         0.99570813 0.99446012]\n",
      " [0.6339168  0.68625679 0.63763128 ... 0.99570813 1.         0.99991588]\n",
      " [0.63315839 0.68483481 0.6368058  ... 0.99446012 0.99991588 1.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.11756978],\n",
       "       [-0.11756978,  1.        ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from patsy import dmatrices\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "numeric_df = iris._get_numeric_data()\n",
    "numeric_df.head()\n",
    "print(np.corrcoef(numeric_df))\n",
    "\n",
    "# it looks like serpal_length has correlation > .5 with each of the other variables\n",
    "\n",
    "sep = iris['sepal_width']\n",
    "pet = iris['petal_length']\n",
    "np.corrcoef(sep, pet)           #-.42\n",
    "np.corrcoef(iris['sepal_length'], iris['sepal_width'])   #.11\n",
    "\n",
    "# We can see that sepal_width and petal_length are negativly correlation at 42%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3a: Practice with the random forest classifier\n",
    "\n",
    "Now that you have learned how to perform supervised machine learning using a variety of algorithms, lets practice using a new algorithm we haven't looked at yet: the Random Forest Classifier.  The random forest classifier builds multiple decision trees and merges them together.  Review the sklearn [online documentation for the RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).  For this task:\n",
    "\n",
    "1. Perform a 10-fold cross-validation strategy to see how well the random forest classifier performs with the iris data\n",
    "2. Use a boxplot to show the distribution of accuracy\n",
    "3. Use the `fit` and `predict` functions to see how well it performs with the testing data.\n",
    "4. Plot the confusion matrix\n",
    "5. Print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.loc[:,'sepal_length':'petal_width'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = iris['species'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessing.robust_scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt, Xv, Yt, Yv = model_selection.train_test_split(X, Y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = model_selection.KFold(n_splits=10, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'LogisticRegression' : np.zeros(10),\n",
    "    'LinearDiscriminantAnalysis' : np.zeros(10),\n",
    "    'KNeighborsClassifier' : np.zeros(10),\n",
    "    'DecisionTreeClassifier' : np.zeros(10),\n",
    "    'GaussianNB' : np.zeros(10),\n",
    "    'SVC' : np.zeros(10),\n",
    "    'RandomForestClassifier': np.zeros(10)\n",
    "}\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LogisticRegression object prepared for a multinomial outcome validation set.\n",
    "alg = RandomForestClassifier()\n",
    "\n",
    "# Execute the cross-validation strategy\n",
    "results['RandomForestClassifier'] = model_selection.cross_val_score(alg, Xt, Yt, cv=kfold, \n",
    "                                                                scoring=\"accuracy\", error_score=np.nan)\n",
    "\n",
    "# Take a look at the scores for each of the 10-fold runs.\n",
    "results['RandomForestClassifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).plot(kind=\"box\", rot=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LinearDiscriminantAnalysis object with defaults.\n",
    "alg = RandomForestClassifier()\n",
    "\n",
    "# Create a new model using all of the training data.\n",
    "alg.fit(Xt, Yt)\n",
    "\n",
    "# Using the testing data, predict the iris species.\n",
    "predictions = alg.predict(Xv)\n",
    "\n",
    "# Let's see the predictions\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(Yv, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['versicolor', 'virginica', 'setosa']\n",
    "cm = confusion_matrix(Yv, predictions, labels=labels)\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
